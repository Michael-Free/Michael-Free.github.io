{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Michael Free I'm passionate about IT infrastructure, automation, and building robust systems. With expertise across PowerShell, Python, containerization, and configuration management, I specialize in creating efficient solutions and streamlining operations. \"First, solve the problem. Then, write the code.\" \u2014 John Johnson","title":"Home"},{"location":"index.html#michael-free","text":"I'm passionate about IT infrastructure, automation, and building robust systems. With expertise across PowerShell, Python, containerization, and configuration management, I specialize in creating efficient solutions and streamlining operations.","title":"Michael Free"},{"location":"index.html#_1","text":"\"First, solve the problem. Then, write the code.\" \u2014 John Johnson","title":""},{"location":"about.html","text":"Michael Free IT Professional | System Administrator | DevOps & Automation Specialist About Me \"A versatile automation, infrastructure, sales, and support specialist.\" I am an IT professional with a deep-seated drive to automate processes and build efficient, reliable systems. Based in Waterloo Region, Canada's renowned tech capital, and with many years of experience working in Toronto's dynamic market, I've built a career across a uniquely broad spectrum of organizations. I have directly contributed to projects, support, and technology sales for non-profits, healthcare providers, municipal governments, Fortune 500 companies, and especially small and medium-sized businesses. This diverse exposure has given me a keen understanding of the distinct technological and operational challenges each sector faces. My approach is automation-first. In my current role, I've developed scripts and frameworks in PowerShell, Python, and Ansible that have significantly improved our team's efficiency. I've automated onboarding workflows, created software deployment packages, and built systems that manage everything from domain migrations to vulnerability scanning. I take pride in seeing a process that used to take hours or days become something that runs reliably in the background in minutes. I have extensive experience working closely with sales teams as a solutions architect, where I translated technical capabilities into compelling business value to win new business and guide customer success. This involved everything from architecting complex datacenter solutions and navigating intricate software licensing and copyright landscapes during the sales cycle to building detailed proof-of-concepts that de-risked projects and demonstrated tangible outcomes for clients. My technical foundation is built on heavy administration skills across both Linux and Windows Server environments. I have deep, hands-on experience with container orchestration using Kubernetes, and virtualization/infrastructure platforms including VMware, Proxmox, and LXD. I manage a wide array of web services and am familiar with deploying and managing workloads in major hyperscaler cloud environments, including Azure, AWS, and GCP. My expertise extends into specialized areas such as cybersecurity, where I've implemented vulnerability management and secure authentication systems, and digital signage/kiosk management, where I've designed and automated entire deployment and content systems from the ground up. I believe in learning by doing, and my GitHub repositories reflect that hands-on philosophy. I enjoy creating tools that solve real problems\u2014whether it's a script to inventory all hardware on a network, a project to automate a full Drupal installation, or building a proof-of-concept Bitcoin Cash ATM from scratch. I was also part of a team that developed a decentralized library system, which was a semi-finalist at a major blockchain hackathon. These projects allow me to explore new technologies and deepen my practical skills. My experience is broad by design. I've worked on the front lines of technical support, built infrastructure as code in DevOps environments, and provided strategic presales consultation. This gives me a valuable perspective: I understand not just how to build and fix systems, but also how technology decisions align with business needs, compliance requirements, and budgetary realities across any organization. I hold certifications from CompTIA, Microsoft, and others, but I consider my greatest skill to be my ability to listen to a problem, break it down, and engineer a sustainable solution. I thrive on collaboration, whether it's working within an IT team, partnering with sales to win new business, or explaining technical concepts to stakeholders. At my core, I am a builder and a problem-solver who is passionate about using technology to make operations smoother, more secure, and more effective.","title":"About"},{"location":"about.html#michael-free","text":"","title":"Michael Free"},{"location":"about.html#it-professional-system-administrator-devops-automation-specialist","text":"","title":"IT Professional | System Administrator | DevOps &amp; Automation Specialist"},{"location":"about.html#about-me","text":"","title":"About Me"},{"location":"about.html#a-versatile-automation-infrastructure-sales-and-support-specialist","text":"I am an IT professional with a deep-seated drive to automate processes and build efficient, reliable systems. Based in Waterloo Region, Canada's renowned tech capital, and with many years of experience working in Toronto's dynamic market, I've built a career across a uniquely broad spectrum of organizations. I have directly contributed to projects, support, and technology sales for non-profits, healthcare providers, municipal governments, Fortune 500 companies, and especially small and medium-sized businesses. This diverse exposure has given me a keen understanding of the distinct technological and operational challenges each sector faces. My approach is automation-first. In my current role, I've developed scripts and frameworks in PowerShell, Python, and Ansible that have significantly improved our team's efficiency. I've automated onboarding workflows, created software deployment packages, and built systems that manage everything from domain migrations to vulnerability scanning. I take pride in seeing a process that used to take hours or days become something that runs reliably in the background in minutes. I have extensive experience working closely with sales teams as a solutions architect, where I translated technical capabilities into compelling business value to win new business and guide customer success. This involved everything from architecting complex datacenter solutions and navigating intricate software licensing and copyright landscapes during the sales cycle to building detailed proof-of-concepts that de-risked projects and demonstrated tangible outcomes for clients. My technical foundation is built on heavy administration skills across both Linux and Windows Server environments. I have deep, hands-on experience with container orchestration using Kubernetes, and virtualization/infrastructure platforms including VMware, Proxmox, and LXD. I manage a wide array of web services and am familiar with deploying and managing workloads in major hyperscaler cloud environments, including Azure, AWS, and GCP. My expertise extends into specialized areas such as cybersecurity, where I've implemented vulnerability management and secure authentication systems, and digital signage/kiosk management, where I've designed and automated entire deployment and content systems from the ground up. I believe in learning by doing, and my GitHub repositories reflect that hands-on philosophy. I enjoy creating tools that solve real problems\u2014whether it's a script to inventory all hardware on a network, a project to automate a full Drupal installation, or building a proof-of-concept Bitcoin Cash ATM from scratch. I was also part of a team that developed a decentralized library system, which was a semi-finalist at a major blockchain hackathon. These projects allow me to explore new technologies and deepen my practical skills. My experience is broad by design. I've worked on the front lines of technical support, built infrastructure as code in DevOps environments, and provided strategic presales consultation. This gives me a valuable perspective: I understand not just how to build and fix systems, but also how technology decisions align with business needs, compliance requirements, and budgetary realities across any organization. I hold certifications from CompTIA, Microsoft, and others, but I consider my greatest skill to be my ability to listen to a problem, break it down, and engineer a sustainable solution. I thrive on collaboration, whether it's working within an IT team, partnering with sales to win new business, or explaining technical concepts to stakeholders. At my core, I am a builder and a problem-solver who is passionate about using technology to make operations smoother, more secure, and more effective.","title":"\"A versatile automation, infrastructure, sales, and support specialist.\""},{"location":"contact.html","text":"Connect with Mike Whether you\u2019re looking for help with automation, technical support, IT solutions, project consultation, or exploring potential job opportunities, you can easily reach me using the resources below. I\u2019m also happy to share my insights and offer guidance on your projects or goals, so don\u2019t hesitate to connect, ask questions, or collaborate. LinkedIn Connect with me on my LinkedIn Profile. Get in touch by connecting with my via my profile @Michael-Free Feel \"Free\" to shoot me a message, too! GitHub Explore my code projects and get in touch by opening an issue, commenting, or connecting via my profile @Michael-Free . You can also click \u201cFollow\u201d on my profile to stay updated. PowerShell Gallery Explore my PowerShell modules and scripts, or submit feedback, or connect via my profile @Michael-Free You can also click \u201cContact Owners\u201d on one of my projects to get in touch with me.","title":"Connect"},{"location":"contact.html#connect-with-mike","text":"Whether you\u2019re looking for help with automation, technical support, IT solutions, project consultation, or exploring potential job opportunities, you can easily reach me using the resources below. I\u2019m also happy to share my insights and offer guidance on your projects or goals, so don\u2019t hesitate to connect, ask questions, or collaborate.","title":"Connect with Mike"},{"location":"contact.html#linkedin","text":"Connect with me on my LinkedIn Profile. Get in touch by connecting with my via my profile @Michael-Free Feel \"Free\" to shoot me a message, too!","title":"LinkedIn"},{"location":"contact.html#github","text":"Explore my code projects and get in touch by opening an issue, commenting, or connecting via my profile @Michael-Free . You can also click \u201cFollow\u201d on my profile to stay updated.","title":"GitHub"},{"location":"contact.html#powershell-gallery","text":"Explore my PowerShell modules and scripts, or submit feedback, or connect via my profile @Michael-Free You can also click \u201cContact Owners\u201d on one of my projects to get in touch with me.","title":"PowerShell Gallery"},{"location":"experience.html","text":"Michael Free Experience IT Technician / System Administrator Public Sector (2021 - Present) Spearheaded an automation-first strategy using PowerShell, Ansible, and Python, reducing manual workloads and improving team efficiency by over 70% in key areas such as user onboarding and software deployment. Automated Active Directory and Office 365 onboarding/offboarding, cutting provisioning time by 70%. Developed 80+ standardized software deployment packages using PowerShell App Deployment Toolkit (PSADT) for consistent, silent rollouts. Built a custom Python/PowerShell framework for remote domain migration of PCs, eliminating the need for on-site visits. Created automated Windows 10 deployment images and post-install configuration scripts, reducing setup time from days to minutes per device. Automated routine maintenance (log cleanup, service restarts) and audit reporting (license usage, inactive accounts) with Ansible and PowerShell. Scripted comprehensive Active Directory audit reports using PowerShell to monitor user accounts, device compliance, group memberships, and licensing alignment. Implemented OpenVAS vulnerability scanning across public and staff networks, proactively identifying and remediating critical risks. Led organization-wide SSL/TLS implementation, replacing insecure self-signed certificates with CA-signed certificates across internal applications, websites, and services that previously operated without encryption. Automated certificate deployment and renewal using Ansible playbooks to ensure continuous compliance. Introduced Yubikeys for IT team multi-factor authentication and migrated credential storage from spreadsheets to a centralized password management solution. Conducted full IT asset inventory via custom PowerShell scripts, pulling hardware and software data directly from Active Directory. Migrated IT asset tracking from spreadsheets and JIRA Assets to Snipe-IT, establishing a centralized, searchable inventory database. Built a custom Python-based kiosk application that interacted with Snipe-IT\u2019s REST API to streamline asset operations. The kiosk featured barcode scanning via webcam to perform fast check-ins, check-outs, and label printing, reducing manual data entry and improving inventory accuracy. Created and maintained PowerShell modules (SnipeItPS) to automate inventory reporting, audits, and bulk updates directly from Active Directory and other IT systems. Led migration from Spiceworks to JIRA Service Management (and later to osTicket) with zero downtime, including parsing and importing a decade of historical ticket data using a custom Python script. Assisted in the rebuild of a Windows Domain Controller and developed Group Policy Objects (GPOs) for organization-wide user and device management. Deployed and managed Windows/Linux virtual machines on VMware vSphere and assisted with Azure cloud deployments using LXD containers. Migrated digital signage infrastructure to a cost-effective, automated solution using Home Assistant, reducing support calls and energy consumption. Managed vendor, reseller, and distributor relationships for procurement of software/hardware assets and technical support. Prepared technical reports, project proposals, and capital/operating expenditure plans for management and stakeholders. Provided daily Tier 1\u20133 support for 150+ users and 250+ systems, including public-access PCs and specialized equipment. Built and maintained an internal knowledge base using BookStack, documenting systems, procedures, and projects. Engineered a custom digital signage platform using Debian, preseeding, custom .deb packages, and Ansible for centralized management. Coordinated and technically supported a live HAM radio event with the International Space Station, streamed via OBS Studio and covered by local media (CTV, CBC). Piloted package management solutions (Chocolatey, WinGet) to automate software updates and accelerate Windows 11 deployment. Tier 3 Platform Support Specialist Cybersecurity Vendor (2020 - 2021) Provided Tier 3 technical support for a security-focused SaaS platform, troubleshooting complex issues within Linux-based virtual appliances (CentOS/Ubuntu), network configurations, firewall rules, and virtualization environments. Investigated and validated security alerts, analyzing false-positive Common Vulnerability and Exposures (CVEs) to maintain platform accuracy and customer trust. Diagnosed and resolved issues with the OpenVAS (Open Vulnerability Assessment Scanner) engine, including logging, configuration, and performance optimization. Responded to and triaged security incidents generated by the platform, providing initial analysis and recommending mitigation steps to customers. Served as a critical liaison between customers and engineering teams, escalating software bugs, feature gaps, and technical roadblocks to drive product improvements. Created and maintained technical documentation, runbooks, and training materials to onboard new team members and improve team readiness. Managed support workflows and customer communications using JIRA and Zendesk, ensuring clear tracking and timely resolution of cases. Collaborated proactively with engineering and product teams to communicate edge-case scenarios and user feedback, contributing to platform usability and support process enhancements. DevOps / System Administrator (Build and Release) Online Gaming & Betting (2018 - 2020) Automated infrastructure provisioning, configuration, and decommissioning across AWS, GCP, DigitalOcean, and on-premise Proxmox environments using Terraform and Ansible. Built and maintained Kubernetes Helm Charts to standardize and streamline the deployment of containerized applications across development and production. Collaborated with development teams to establish and enhance CI/CD pipelines and automated environment creation using open-source tooling. Managed a heterogeneous environment of Linux/Windows servers, Linux/Windows desktops, and macOS systems across development and staging. Conducted system hardening, vulnerability assessments, and implemented security patches in coordination with the Security Administrator to ensure compliance. Created and maintained a comprehensive hardware and software asset inventory system using open-source tools for internal tracking and compliance. Owned internal user lifecycle management, including account provisioning, permissions management, and access control across multiple platforms and services. Developed and maintained technical documentation for system architectures, deployment procedures, and operational runbooks. Contributed to scalable and reliable infrastructure supporting applications in regulated, high-availability industries including online gaming, blockchain, and casino platforms. Datacenter Solutions Specialist (Pre-Sales) IT Solutions Provider / Value Added Reseller (2015 - 2018) Acted as a subject matter expert on Lenovo datacenter technologies, providing presales technical consultation for servers, storage, networking, and hyperconverged infrastructure solutions tailored to client business needs. Designed integrated infrastructure solutions aligned with performance, scalability, and budgetary requirements, encompassing compute, virtualization, storage (SAN/NAS), and associated software ecosystems. Developed comprehensive solution architectures, including technical diagrams, Bills of Materials (BOMs), and Statements of Work (SOWs) for deployments involving VMware solutions and other virtualization platforms. Maintained expert-level knowledge of Lenovo\u2019s product roadmap, certifications, and enterprise deployment best practices across server, storage, networking, and hyperconverged portfolios. Collaborated with vendors, distributors, and resellers to ensure competitive pricing, product availability, and accurate configuration of solutions, including integrated stacks with key partners like VMware. Validated and optimized hardware and software configurations for large-scale datacenter deployments, balancing cost, compatibility, and future scalability across compute, storage, and networking layers. Provided internal enablement and maintained technical credibility through continuous self-training on emerging technologies, including advancements in virtualization, storage architectures, and hyperconverged infrastructure. Served as a trusted technical resource for complex datacenter inquiries, guiding stakeholders through purchasing decisions and deployment strategies for servers, storage, networking, and integrated systems. Technical Consultant Digital Signage / Kiosk / ATM Solutions (2013 - 2015) Collaborated with sales and development teams to deploy tailored remote device management and digital signage solutions for enterprise clients. Developed and maintained XML configuration templates to integrate RS232 serial command sets into proprietary remote management software. Engineered automation scripts in PowerShell, Bash, and Batch to control, monitor, and manage remote field devices across diverse environments. Created technical proof-of-concepts (PoCs) for digital signage monitoring software and IoT solutions using Raspberry Pi and Arduino to demonstrate product enhancements. Supported the full sales lifecycle by assisting with technical sales calls, product demonstrations, and solution implementations. Researched and compiled RS232 command libraries to enable remote management and control of field-deployed digital signage hardware. Translated client requirements into functional prototypes and PoCs, guiding both technical feasibility and the sales process. Microsoft Licensing Specialist Microsoft Support / Value Added Reseller (2007 - 2013) Acted as a subject matter expert for Microsoft licensing across Canada and the U.S., providing pre-sales consultation to internal sales teams and prospective clients. Interpreted and communicated complex Microsoft Use Rights, Software Assurance benefits, and licensing entitlements based on product SKUs and agreement terms. Created formal, accurate quotes aligned with appropriate pricing tiers and agreements (government, education, charity, etc.) using manufacturer part numbers. Maintained deep, up-to-date knowledge of evolving Microsoft licensing models and transition periods between volume licensing programs. Used consultative selling to support pre-sales activities related to Microsoft Licensing Programs, products, and solutions. Facilitated training sessions for sales teams on products, services, licensing, and program updates. Served as a liaison between Sales and Product/Partner Management to identify opportunities for improved product, program, and partner alignment. Provided frontline licensing support via Microsoft\u2019s 1\u2011800\u2011MICROSOFT hotline, assisting business customers, partners, and resellers. Researched and clarified license entitlements, downgrade rights, and compliance requirements for diverse client needs. Educated non\u2011technical customers and small\u2011business owners on product availability, licensing options, and purchasing channels. Certifications CompTIA A+ (2013) Earned CompTIA A+, validating hands-on skills in hardware, operating systems, networking, security, and technical troubleshooting. Demonstrated ability to install, configure, maintain, and support end-user devices in a professional IT environment CompTIA Server+ (2013) Earned CompTIA Server+, validating hands-on skills in server hardware installation, configuration, maintenance, virtualization, and disaster recovery Demonstrated ability to deploy, manage, and troubleshoot on-premises server infrastructure in enterprise environments Microsoft Licensing Solutions for Enterprise Organizations (2012) Completed Microsoft Licensing Solutions for Enterprise Organizations, demonstrating understanding of Microsoft volume licensing models, compliance, and cost optimization Gained expertise in selecting and managing enterprise Microsoft licensing solutions aligned with organizational needs and governance requirements Microsoft Licensing Solutions for Small & Medium Sized Organizations (2012) Completed Microsoft Licensing Solutions for Small & Medium Sized Organizations, demonstrating knowledge of Microsoft licensing programs tailored to SMB environments Developed ability to recommend compliant, cost-effective Microsoft licensing solutions aligned with business size, growth, and operational needs Lenovo Datacenter Technical Sales Professional (2017) Earned Lenovo Datacenter Technical Sales Professional (2017), validating expertise in Lenovo server, storage, and SDI portfolios and their application to customer requirements Demonstrated ability to position data center solutions by workload, build basic configurations, and leverage Lenovo Systems Management tools (XClarity, XClarity Controller, CMM) Validates skills in mapping customer business and technical requirements to appropriate Lenovo hardware and solution families Confirms competency in building and proposing basic server and storage configurations aligned with stated use cases Supports proven capability to translate technical features into value-driven solutions during technical sales and pre-sales engagements Education Business Mangagement Studies Conestoga College (2009) Advanced Diploma (3 years) \u2014 Developed broad understanding of business functions including finance, accounting, marketing, sales, HR, operations, and project management Gained practical skills in modern management techniques and business databases, applicable to corporate, government, non-profit, and entrepreneurial environments Prepared as a versatile management generalist, capable of strategic decision-making, team leadership, and adapting to evolving business needs Skills Automation & Scripting PowerShell (including PSADT) Python scripting and frameworks Ansible (automation & playbooks) Bash/Batch scripting Terraform (infrastructure automation) Systems & Infrastructure Windows Server administration Linux administration (Debian, Ubuntu, CentOS) Active Directory & Office 365 management Group Policy Objects (GPO) creation and management Virtualization: VMware vSphere, Proxmox, LXD Container orchestration: Kubernetes & Helm Charts Cloud Platforms: Azure, AWS, GCP DevOps & CI/CD Infrastructure as Code (Terraform, Ansible) CI/CD pipeline creation and automation Software deployment automation (PSADT, Chocolatey, WinGet) System hardening & vulnerability management (OpenVAS) Networking & Security SSL/TLS deployment and certificate management Multi-factor authentication (Yubikeys) Firewall & network troubleshooting Cybersecurity incident triage and vulnerability scanning IT Operations & Asset Management IT asset tracking and inventory (Snipe-IT, spreadsheets, JIRA) Digital signage/kiosk/ATM systems management Ticketing & support systems (JIRA, osTicket, Zendesk) Hardware & software auditing Knowledge base creation (BookStack) Technical Sales & Pre-Sales Solutions architecture and consultation Datacenter solutions design (Lenovo, VMware, hyperconverged infrastructure) Microsoft Licensing expertise (enterprise & SMB) Vendor and client relationship management Proof-of-concept (PoC) creation and demonstrations Project & Team Skills Cross-functional collaboration (IT, sales, engineering) Process optimization and efficiency improvement Documentation, runbooks, and technical reporting Project planning and execution Client-facing technical consultation","title":"Experience"},{"location":"experience.html#michael-free","text":"","title":"Michael Free"},{"location":"experience.html#experience","text":"","title":"Experience"},{"location":"experience.html#it-technician-system-administrator","text":"","title":"IT Technician / System Administrator"},{"location":"experience.html#public-sector-2021-present","text":"Spearheaded an automation-first strategy using PowerShell, Ansible, and Python, reducing manual workloads and improving team efficiency by over 70% in key areas such as user onboarding and software deployment. Automated Active Directory and Office 365 onboarding/offboarding, cutting provisioning time by 70%. Developed 80+ standardized software deployment packages using PowerShell App Deployment Toolkit (PSADT) for consistent, silent rollouts. Built a custom Python/PowerShell framework for remote domain migration of PCs, eliminating the need for on-site visits. Created automated Windows 10 deployment images and post-install configuration scripts, reducing setup time from days to minutes per device. Automated routine maintenance (log cleanup, service restarts) and audit reporting (license usage, inactive accounts) with Ansible and PowerShell. Scripted comprehensive Active Directory audit reports using PowerShell to monitor user accounts, device compliance, group memberships, and licensing alignment. Implemented OpenVAS vulnerability scanning across public and staff networks, proactively identifying and remediating critical risks. Led organization-wide SSL/TLS implementation, replacing insecure self-signed certificates with CA-signed certificates across internal applications, websites, and services that previously operated without encryption. Automated certificate deployment and renewal using Ansible playbooks to ensure continuous compliance. Introduced Yubikeys for IT team multi-factor authentication and migrated credential storage from spreadsheets to a centralized password management solution. Conducted full IT asset inventory via custom PowerShell scripts, pulling hardware and software data directly from Active Directory. Migrated IT asset tracking from spreadsheets and JIRA Assets to Snipe-IT, establishing a centralized, searchable inventory database. Built a custom Python-based kiosk application that interacted with Snipe-IT\u2019s REST API to streamline asset operations. The kiosk featured barcode scanning via webcam to perform fast check-ins, check-outs, and label printing, reducing manual data entry and improving inventory accuracy. Created and maintained PowerShell modules (SnipeItPS) to automate inventory reporting, audits, and bulk updates directly from Active Directory and other IT systems. Led migration from Spiceworks to JIRA Service Management (and later to osTicket) with zero downtime, including parsing and importing a decade of historical ticket data using a custom Python script. Assisted in the rebuild of a Windows Domain Controller and developed Group Policy Objects (GPOs) for organization-wide user and device management. Deployed and managed Windows/Linux virtual machines on VMware vSphere and assisted with Azure cloud deployments using LXD containers. Migrated digital signage infrastructure to a cost-effective, automated solution using Home Assistant, reducing support calls and energy consumption. Managed vendor, reseller, and distributor relationships for procurement of software/hardware assets and technical support. Prepared technical reports, project proposals, and capital/operating expenditure plans for management and stakeholders. Provided daily Tier 1\u20133 support for 150+ users and 250+ systems, including public-access PCs and specialized equipment. Built and maintained an internal knowledge base using BookStack, documenting systems, procedures, and projects. Engineered a custom digital signage platform using Debian, preseeding, custom .deb packages, and Ansible for centralized management. Coordinated and technically supported a live HAM radio event with the International Space Station, streamed via OBS Studio and covered by local media (CTV, CBC). Piloted package management solutions (Chocolatey, WinGet) to automate software updates and accelerate Windows 11 deployment.","title":"Public Sector (2021 - Present)"},{"location":"experience.html#tier-3-platform-support-specialist","text":"","title":"Tier 3 Platform Support Specialist"},{"location":"experience.html#cybersecurity-vendor-2020-2021","text":"Provided Tier 3 technical support for a security-focused SaaS platform, troubleshooting complex issues within Linux-based virtual appliances (CentOS/Ubuntu), network configurations, firewall rules, and virtualization environments. Investigated and validated security alerts, analyzing false-positive Common Vulnerability and Exposures (CVEs) to maintain platform accuracy and customer trust. Diagnosed and resolved issues with the OpenVAS (Open Vulnerability Assessment Scanner) engine, including logging, configuration, and performance optimization. Responded to and triaged security incidents generated by the platform, providing initial analysis and recommending mitigation steps to customers. Served as a critical liaison between customers and engineering teams, escalating software bugs, feature gaps, and technical roadblocks to drive product improvements. Created and maintained technical documentation, runbooks, and training materials to onboard new team members and improve team readiness. Managed support workflows and customer communications using JIRA and Zendesk, ensuring clear tracking and timely resolution of cases. Collaborated proactively with engineering and product teams to communicate edge-case scenarios and user feedback, contributing to platform usability and support process enhancements.","title":"Cybersecurity Vendor (2020 - 2021)"},{"location":"experience.html#devops-system-administrator-build-and-release","text":"","title":"DevOps / System Administrator (Build and Release)"},{"location":"experience.html#online-gaming-betting-2018-2020","text":"Automated infrastructure provisioning, configuration, and decommissioning across AWS, GCP, DigitalOcean, and on-premise Proxmox environments using Terraform and Ansible. Built and maintained Kubernetes Helm Charts to standardize and streamline the deployment of containerized applications across development and production. Collaborated with development teams to establish and enhance CI/CD pipelines and automated environment creation using open-source tooling. Managed a heterogeneous environment of Linux/Windows servers, Linux/Windows desktops, and macOS systems across development and staging. Conducted system hardening, vulnerability assessments, and implemented security patches in coordination with the Security Administrator to ensure compliance. Created and maintained a comprehensive hardware and software asset inventory system using open-source tools for internal tracking and compliance. Owned internal user lifecycle management, including account provisioning, permissions management, and access control across multiple platforms and services. Developed and maintained technical documentation for system architectures, deployment procedures, and operational runbooks. Contributed to scalable and reliable infrastructure supporting applications in regulated, high-availability industries including online gaming, blockchain, and casino platforms.","title":"Online Gaming &amp; Betting (2018 - 2020)"},{"location":"experience.html#datacenter-solutions-specialist-pre-sales","text":"","title":"Datacenter Solutions Specialist (Pre-Sales)"},{"location":"experience.html#it-solutions-provider-value-added-reseller-2015-2018","text":"Acted as a subject matter expert on Lenovo datacenter technologies, providing presales technical consultation for servers, storage, networking, and hyperconverged infrastructure solutions tailored to client business needs. Designed integrated infrastructure solutions aligned with performance, scalability, and budgetary requirements, encompassing compute, virtualization, storage (SAN/NAS), and associated software ecosystems. Developed comprehensive solution architectures, including technical diagrams, Bills of Materials (BOMs), and Statements of Work (SOWs) for deployments involving VMware solutions and other virtualization platforms. Maintained expert-level knowledge of Lenovo\u2019s product roadmap, certifications, and enterprise deployment best practices across server, storage, networking, and hyperconverged portfolios. Collaborated with vendors, distributors, and resellers to ensure competitive pricing, product availability, and accurate configuration of solutions, including integrated stacks with key partners like VMware. Validated and optimized hardware and software configurations for large-scale datacenter deployments, balancing cost, compatibility, and future scalability across compute, storage, and networking layers. Provided internal enablement and maintained technical credibility through continuous self-training on emerging technologies, including advancements in virtualization, storage architectures, and hyperconverged infrastructure. Served as a trusted technical resource for complex datacenter inquiries, guiding stakeholders through purchasing decisions and deployment strategies for servers, storage, networking, and integrated systems.","title":"IT Solutions Provider / Value Added Reseller (2015 - 2018)"},{"location":"experience.html#technical-consultant","text":"","title":"Technical Consultant"},{"location":"experience.html#digital-signage-kiosk-atm-solutions-2013-2015","text":"Collaborated with sales and development teams to deploy tailored remote device management and digital signage solutions for enterprise clients. Developed and maintained XML configuration templates to integrate RS232 serial command sets into proprietary remote management software. Engineered automation scripts in PowerShell, Bash, and Batch to control, monitor, and manage remote field devices across diverse environments. Created technical proof-of-concepts (PoCs) for digital signage monitoring software and IoT solutions using Raspberry Pi and Arduino to demonstrate product enhancements. Supported the full sales lifecycle by assisting with technical sales calls, product demonstrations, and solution implementations. Researched and compiled RS232 command libraries to enable remote management and control of field-deployed digital signage hardware. Translated client requirements into functional prototypes and PoCs, guiding both technical feasibility and the sales process.","title":"Digital Signage / Kiosk / ATM Solutions (2013 - 2015)"},{"location":"experience.html#microsoft-licensing-specialist","text":"","title":"Microsoft Licensing Specialist"},{"location":"experience.html#microsoft-support-value-added-reseller-2007-2013","text":"Acted as a subject matter expert for Microsoft licensing across Canada and the U.S., providing pre-sales consultation to internal sales teams and prospective clients. Interpreted and communicated complex Microsoft Use Rights, Software Assurance benefits, and licensing entitlements based on product SKUs and agreement terms. Created formal, accurate quotes aligned with appropriate pricing tiers and agreements (government, education, charity, etc.) using manufacturer part numbers. Maintained deep, up-to-date knowledge of evolving Microsoft licensing models and transition periods between volume licensing programs. Used consultative selling to support pre-sales activities related to Microsoft Licensing Programs, products, and solutions. Facilitated training sessions for sales teams on products, services, licensing, and program updates. Served as a liaison between Sales and Product/Partner Management to identify opportunities for improved product, program, and partner alignment. Provided frontline licensing support via Microsoft\u2019s 1\u2011800\u2011MICROSOFT hotline, assisting business customers, partners, and resellers. Researched and clarified license entitlements, downgrade rights, and compliance requirements for diverse client needs. Educated non\u2011technical customers and small\u2011business owners on product availability, licensing options, and purchasing channels.","title":"Microsoft Support / Value Added Reseller (2007 - 2013)"},{"location":"experience.html#certifications","text":"","title":"Certifications"},{"location":"experience.html#comptia-a-2013","text":"Earned CompTIA A+, validating hands-on skills in hardware, operating systems, networking, security, and technical troubleshooting. Demonstrated ability to install, configure, maintain, and support end-user devices in a professional IT environment","title":"CompTIA A+ (2013)"},{"location":"experience.html#comptia-server-2013","text":"Earned CompTIA Server+, validating hands-on skills in server hardware installation, configuration, maintenance, virtualization, and disaster recovery Demonstrated ability to deploy, manage, and troubleshoot on-premises server infrastructure in enterprise environments","title":"CompTIA Server+ (2013)"},{"location":"experience.html#microsoft-licensing-solutions-for-enterprise-organizations-2012","text":"Completed Microsoft Licensing Solutions for Enterprise Organizations, demonstrating understanding of Microsoft volume licensing models, compliance, and cost optimization Gained expertise in selecting and managing enterprise Microsoft licensing solutions aligned with organizational needs and governance requirements","title":"Microsoft Licensing Solutions for Enterprise Organizations (2012)"},{"location":"experience.html#microsoft-licensing-solutions-for-small-medium-sized-organizations-2012","text":"Completed Microsoft Licensing Solutions for Small & Medium Sized Organizations, demonstrating knowledge of Microsoft licensing programs tailored to SMB environments Developed ability to recommend compliant, cost-effective Microsoft licensing solutions aligned with business size, growth, and operational needs","title":"Microsoft Licensing Solutions for Small &amp; Medium Sized Organizations (2012)"},{"location":"experience.html#lenovo-datacenter-technical-sales-professional-2017","text":"Earned Lenovo Datacenter Technical Sales Professional (2017), validating expertise in Lenovo server, storage, and SDI portfolios and their application to customer requirements Demonstrated ability to position data center solutions by workload, build basic configurations, and leverage Lenovo Systems Management tools (XClarity, XClarity Controller, CMM) Validates skills in mapping customer business and technical requirements to appropriate Lenovo hardware and solution families Confirms competency in building and proposing basic server and storage configurations aligned with stated use cases Supports proven capability to translate technical features into value-driven solutions during technical sales and pre-sales engagements","title":"Lenovo Datacenter Technical Sales Professional (2017)"},{"location":"experience.html#education","text":"","title":"Education"},{"location":"experience.html#business-mangagement-studies","text":"","title":"Business Mangagement Studies"},{"location":"experience.html#conestoga-college-2009","text":"Advanced Diploma (3 years) \u2014 Developed broad understanding of business functions including finance, accounting, marketing, sales, HR, operations, and project management Gained practical skills in modern management techniques and business databases, applicable to corporate, government, non-profit, and entrepreneurial environments Prepared as a versatile management generalist, capable of strategic decision-making, team leadership, and adapting to evolving business needs","title":"Conestoga College (2009)"},{"location":"experience.html#skills","text":"","title":"Skills"},{"location":"experience.html#automation-scripting","text":"PowerShell (including PSADT) Python scripting and frameworks Ansible (automation & playbooks) Bash/Batch scripting Terraform (infrastructure automation)","title":"Automation &amp; Scripting"},{"location":"experience.html#systems-infrastructure","text":"Windows Server administration Linux administration (Debian, Ubuntu, CentOS) Active Directory & Office 365 management Group Policy Objects (GPO) creation and management Virtualization: VMware vSphere, Proxmox, LXD Container orchestration: Kubernetes & Helm Charts Cloud Platforms: Azure, AWS, GCP","title":"Systems &amp; Infrastructure"},{"location":"experience.html#devops-cicd","text":"Infrastructure as Code (Terraform, Ansible) CI/CD pipeline creation and automation Software deployment automation (PSADT, Chocolatey, WinGet) System hardening & vulnerability management (OpenVAS)","title":"DevOps &amp; CI/CD"},{"location":"experience.html#networking-security","text":"SSL/TLS deployment and certificate management Multi-factor authentication (Yubikeys) Firewall & network troubleshooting Cybersecurity incident triage and vulnerability scanning","title":"Networking &amp; Security"},{"location":"experience.html#it-operations-asset-management","text":"IT asset tracking and inventory (Snipe-IT, spreadsheets, JIRA) Digital signage/kiosk/ATM systems management Ticketing & support systems (JIRA, osTicket, Zendesk)","title":"IT Operations &amp; Asset Management"},{"location":"experience.html#hardware-software-auditing","text":"Knowledge base creation (BookStack) Technical Sales & Pre-Sales Solutions architecture and consultation Datacenter solutions design (Lenovo, VMware, hyperconverged infrastructure) Microsoft Licensing expertise (enterprise & SMB) Vendor and client relationship management Proof-of-concept (PoC) creation and demonstrations","title":"Hardware &amp; software auditing"},{"location":"experience.html#project-team-skills","text":"Cross-functional collaboration (IT, sales, engineering) Process optimization and efficiency improvement Documentation, runbooks, and technical reporting Project planning and execution Client-facing technical consultation","title":"Project &amp; Team Skills"},{"location":"projects/ansible.html","text":"Ansible Automation Projects Ansible enables infrastructure as code, allowing me to automate repetitive IT tasks with precision and consistency. By defining desired states in simple YAML playbooks, I transform manual processes into reliable, scalable automation that reduces human error and improves operational predictability. Key Impact: Business Alignment: Translate organizational needs into automated workflows Operational Efficiency: Scale IT capabilities without proportional staffing increases Cost Optimization: Reduce expenses through automation and improved system visibility Security Enhancement: Implement consistent security configurations by default Proactive Management: Shift IT from reactive troubleshooting to proactive maintenance, preventing outages before they occur Reliability: Minimize system fragility through standardized, tested automation Automated Portfolio Website Deployment Pipeline Local Gitea Instance to GitHub Pages Designed and implemented an end-to-end automated deployment workflow using Ansible, integrated directly into a CI/CD pipeline triggered by Gitea Actions, to publish my portfolio website with zero manual intervention. The results are the website are what you are viewing right now. The playbook dynamically retrieves the latest tagged release from a self-hosted Gitea repository, applies consistent versioned naming, and stages the build artifacts locally. It then securely synchronizes the generated site to a GitHub Pages repository, ensuring the public-facing website always reflects the latest approved release. Using Ansible, the deployment process: Detects and downloads the latest release artifact automatically Applies consistent, date-based versioning Cleans and refreshes the target repository safely Copies only the generated site output to production Commits and pushes changes conditionall (only when updates exist) Creates a corresponding GitHub release for traceability Impact: The entire workflow is executed as part of a CI/CD pipeline in Gitea Actions, allowing a single release action in Gitea to automatically build, deploy, version, and publish the website. Key highlights: Infrastructure-as-Code deployment workflow with Ansible CI/CD-triggered execution via Gitea Actions Artifact-based deployments using tagged releases Idempotent publishing logic to prevent unnecessary changes Automated GitHub Pages updates and releases Cross-platform orchestration between self-hosted Gitea and GitHub Impact: Reduced website publishing to a fully automated, repeatable process, eliminated manual deployment errors, and ensured consistent, traceable releases\u2014turning a multi-step deployment into a single automated action. Employee Offboarding Hybrid AD & Microsoft 365 Deprovisioning with Ansible Designed and implemented an end-to-end Ansible-driven employee offboarding system that automates identity deprovisioning across on-prem Active Directory and Microsoft 365. The solution schedules and enforces AD account expirations, validates user data, and performs daily checks for expiring accounts on domain controllers. When an offboarding event is triggered, Ansible securely orchestrates Microsoft Graph PowerShell workflows to disable user sessions, reset passwords, revoke group access, and enforce security controls in Microsoft 365. Key highlights: Hybrid automation spanning Windows domain controllers and cloud services Custom PowerShell functions and modules integrated into Ansible workflows Robust validation and error handling for usernames, email addresses, and dates Security-focused design ensuring timely access revocation and auditability Idempotent, production-ready playbooks suitable for scheduled and event-driven execution Impact: Reduced offboarding time from manual, error-prone processes to a fully automated workflow completed in minutes, significantly improving security posture and operational consistency. Employee Onboarding Automated Hybrid AD, Microsoft 365 & Enterprise Service Provisioning with Ansible Built a comprehensive Ansible-based employee onboarding automation that provisions user access across Active Directory, Microsoft 365, and internal enterprise systems from a single workflow. The playbook creates new Active Directory users, securely generates randomized credentials, and provisions corresponding Microsoft 365 accounts with unique passwords. It integrates PowerShell automation to process CSV exports from network printers, generating and assigning new printer access codes for incoming employees. Additional tasks provision accounts across supporting internal services to ensure day-one readiness. Prior to a ticketing system migration, the automation also integrated directly with Jira, automatically responding to onboarding tickets with status updates and completion details. Key highlights: End-to-end identity provisioning across on-prem and cloud environments Secure password generation and credential handling PowerShell-driven printer access automation using CSV data sources Multi-service account creation beyond AD and M365 Ticket-driven automation with automated Jira responses Idempotent, reusable Ansible playbooks designed for scale Impact: Reduced onboarding time from hours to minutes, eliminated manual provisioning errors, and delivered consistent, auditable access for new employees on their first day. Proactive Service Remediation Public Printing Infrastructure Stability with Ansible Developed a scheduled Ansible automation to proactively stabilize a failing public printing service that frequently required manual Windows service restarts across multiple office locations. Using Ansible with Semaphore, I implemented a daily, off-hours playbook that automatically resets the affected Windows service when all offices were closed. This prevented cascading failures that previously triggered waves of support calls as offices opened throughout the day. Key highlights: Scheduled, unattended remediation using Ansible and Semaphore Windows service automation across distributed environments Proactive reliability engineering instead of reactive support Safe execution window aligned with business hours Impact: Eliminated recurring service outages, significantly reduced support call volume, and freed IT staff from repetitive manual interventions while improving service availability for patrons. Stability for Mission-Critical Systems Accounting System Automation & Remediation with Ansible Implemented a scheduled Ansible playbook to proactively stabilize a mission-critical accounting application running on Windows Server that was prone to service crashes. Prior to automation, failures frequently triggered urgent escalations and operational disruption for the accounting team. The playbook performs a controlled weekly restart of the application services during a safe maintenance window, preventing the recurring crashes that previously required manual intervention. Key highlights: Windows service automation for line-of-business applications Scheduled preventive maintenance using Ansible Zero-touch execution with predictable recovery behavior Business-aligned maintenance windows to avoid user impact Impact: Eliminated recurring outages, prevented high-stress incident escalations, and restored confidence for non-technical stakeholders by ensuring consistent system availability. PII Data Sanitization Public Folder Security on File Servers with Ansible Implemented a scheduled Ansible automation to securely manage a shared file server directory used for inbound scanned documents containing highly sensitive personally identifiable information (PII), including social insurance numbers and banking details. A manual deletion process was initially proposed, requiring staff to regularly clear the directory. This approach was unreliable, difficult to enforce, and vulnerable to being missed during high-priority IT incidents. To eliminate human error, I built an Ansible playbook that securely connects to the file server and automatically deletes the directory contents each evening after business hours. Key highlights: Security-first automation for sensitive data handling Elimination of manual, error-prone processes Scheduled execution outside business hours to avoid operational impact Consistent, auditable enforcement of data retention policies Impact: Significantly reduced the risk of sensitive data exposure, ensured consistent compliance with internal data-handling policies, and removed a fragile manual task from daily IT operations. Account Auditing and Reporting Active Directory & Microsoft 365 with Ansible Designed and implemented an Ansible-based auditing and reporting solution to continuously assess identity and device hygiene across on-prem Active Directory and Microsoft 365. The automation polls domain controllers to identify stale computer objects that have not checked in for extended periods, enabling the IT services team to cross-reference devices against the asset inventory to confirm decommissioning or recovery. This significantly reduced Active Directory object sprawl and improved directory accuracy. The playbook also audits user account activity, identifying inactive, disabled, and locked accounts. These reports were used to validate account lifecycle events against HR-provided employee rosters, reducing missed off-boardings and strengthening the organization\u2019s security posture. In parallel, the automation performs Microsoft 365 user and license audits, correlating cloud accounts with on-prem activity to identify accounts that should be deactivated and licenses reclaimed. Key highlights: Hybrid identity auditing across AD and Microsoft 365 Detection of stale devices and inactive users Cost control through license reclamation Security posture improvement via reduced orphaned accounts CSV-based reporting published to shared locations for cross-team review Impact: Improved directory accuracy, reduced security risk from dormant identities, lowered Microsoft 365 licensing costs, and provided IT leadership with clear, actionable audit data for lifecycle management. Digital Signage Platform Custom Linux Distribution & Automation with Ansible Architected and deployed a fully automated digital signage platform managed end-to-end with Ansible, replacing an unreliable, freemium Windows-based solution that had effectively become abandonware. The legacy system caused frequent outages, frozen players, disruptive OS notifications, and required on-site manual intervention\u2014often involving ladder access to power-cycle devices. Windows updates, advertisements, and OS instability made reliable video playback impossible at scale. To solve this, I built a custom minimal Debian-based distribution, designed specifically for digital signage reliability. The operating system installation was fully automated using Debian preseed, producing a custom ISO with no interactive setup. A dedicated systemd service ensured the latest campaign video played continuously and reliably on boot. A suite of Ansible playbooks provided centralized control of all signage players across multiple remote branches, enabling: Remote start/stop of signage playback Scheduled nightly content updates from a central file server Remote software updates and controlled reboots Fleet-wide management with no physical access required For resiliency, a Cockpit web UI was deployed on each player, allowing manual recovery and control if Ansible connectivity was unavailable. Key highlights: Custom Linux OS engineering for single-purpose reliability Ansible-driven fleet management across geographically distributed sites systemd-based application orchestration Zero-touch provisioning with Debian preseed Fallback web management via Cockpit Impact: Eliminated routine on-site service visits, drastically reduced support calls related to digital signage failures, and transformed digital signage from a recurring operational burden into a stable, self-maintaining platform\u2014freeing the IT services team to focus on higher-value work. SSL Certificate Management Automated SSL Enablement with Ansible Identified and remediated a security gap where internally hosted web applications were operating over unencrypted HTTP, exposing sensitive internal traffic. The organization underestimated the value of SSL due to the perceived complexity of managing custom certificates across multiple systems. Collaborated with web developers to obtain a wildcard SSL certificate aligned with the organization\u2019s domain, eliminating browser warnings and enabling encrypted communication without per-machine certificate installation. Built an Ansible playbook to centrally deploy and renew SSL certificates across multiple internal web applications\u2014including the inventory system, ticketing platform, and staff intranet\u2014with a single execution. This ensured consistent HTTPS enforcement and simplified certificate lifecycle management. As the environment evolved, the applications were consolidated behind HAProxy, and the automation was extended to update certificates and reload services centrally. Key highlights: Security posture improvement through encrypted internal communications Wildcard SSL strategy to simplify trust management One-click certificate deployment and renewal using Ansible Cross-team collaboration with development teams Scalable evolution to centralized TLS termination with HAProxy Impact: Eliminated insecure HTTP usage, removed browser trust warnings, simplified certificate renewals, and ensured consistent, encrypted access to internal services with minimal operational overhead. Ubuntu Website OS & Containerized Development Automation with Ansible Modernized the corporate website infrastructure by transitioning from a single, static Ubuntu VM to LXC (Linux container) hosting, enabling faster deployments, easier updates, and greater development agility. Using Ansible, I automated website backups, container snapshots, and local replication of the production environment. This allowed web developers to work locally on an exact copy of the live site without risking downtime or production errors. Key highlights: Containerized hosting for improved deployment velocity and scalability Automated backups and snapshots for website protection and quick recovery Local development replication for safe, parallel testing and feature development Reduced errors and downtime by removing manual deployment steps Impact: Empowered web developers to iterate rapidly while ensuring the corporate website remained stable and highly available, all with minimal manual intervention. Zero-Touch Website OS Upgrade Ubuntu OS Upgrade with Ansible Automated the upgrade of a corporate website VM from Ubuntu 22.04 to 24.04, eliminating a previously manual, multi-hour process that risked significant downtime. Using Ansible playbooks and a staged local VM environment, I implemented a zero-touch upgrade process that reduced website downtime from hours to just a few minutes. The solution was fully repeatable and required minimal manual intervention, allowing operations to run smoothly without disrupting users. Key highlights: Zero-touch OS upgrades for minimal downtime Staged testing environment to validate upgrades before production Automated, repeatable playbooks for consistent results Business continuity maintained with near-invisible service impact Impact: Transformed a time-consuming, risky maintenance task into a fast, reliable, automated operation, impressing stakeholders and improving operational confidence in future upgrades.","title":"Ansible"},{"location":"projects/ansible.html#ansible-automation-projects","text":"Ansible enables infrastructure as code, allowing me to automate repetitive IT tasks with precision and consistency. By defining desired states in simple YAML playbooks, I transform manual processes into reliable, scalable automation that reduces human error and improves operational predictability. Key Impact: Business Alignment: Translate organizational needs into automated workflows Operational Efficiency: Scale IT capabilities without proportional staffing increases Cost Optimization: Reduce expenses through automation and improved system visibility Security Enhancement: Implement consistent security configurations by default Proactive Management: Shift IT from reactive troubleshooting to proactive maintenance, preventing outages before they occur Reliability: Minimize system fragility through standardized, tested automation","title":"Ansible Automation Projects"},{"location":"projects/ansible.html#automated-portfolio-website-deployment-pipeline","text":"","title":"Automated Portfolio Website Deployment Pipeline"},{"location":"projects/ansible.html#local-gitea-instance-to-github-pages","text":"Designed and implemented an end-to-end automated deployment workflow using Ansible, integrated directly into a CI/CD pipeline triggered by Gitea Actions, to publish my portfolio website with zero manual intervention. The results are the website are what you are viewing right now. The playbook dynamically retrieves the latest tagged release from a self-hosted Gitea repository, applies consistent versioned naming, and stages the build artifacts locally. It then securely synchronizes the generated site to a GitHub Pages repository, ensuring the public-facing website always reflects the latest approved release. Using Ansible, the deployment process: Detects and downloads the latest release artifact automatically Applies consistent, date-based versioning Cleans and refreshes the target repository safely Copies only the generated site output to production Commits and pushes changes conditionall (only when updates exist) Creates a corresponding GitHub release for traceability Impact: The entire workflow is executed as part of a CI/CD pipeline in Gitea Actions, allowing a single release action in Gitea to automatically build, deploy, version, and publish the website. Key highlights: Infrastructure-as-Code deployment workflow with Ansible CI/CD-triggered execution via Gitea Actions Artifact-based deployments using tagged releases Idempotent publishing logic to prevent unnecessary changes Automated GitHub Pages updates and releases Cross-platform orchestration between self-hosted Gitea and GitHub Impact: Reduced website publishing to a fully automated, repeatable process, eliminated manual deployment errors, and ensured consistent, traceable releases\u2014turning a multi-step deployment into a single automated action.","title":"Local Gitea Instance to GitHub Pages"},{"location":"projects/ansible.html#employee-offboarding","text":"","title":"Employee Offboarding"},{"location":"projects/ansible.html#hybrid-ad-microsoft-365-deprovisioning-with-ansible","text":"Designed and implemented an end-to-end Ansible-driven employee offboarding system that automates identity deprovisioning across on-prem Active Directory and Microsoft 365. The solution schedules and enforces AD account expirations, validates user data, and performs daily checks for expiring accounts on domain controllers. When an offboarding event is triggered, Ansible securely orchestrates Microsoft Graph PowerShell workflows to disable user sessions, reset passwords, revoke group access, and enforce security controls in Microsoft 365. Key highlights: Hybrid automation spanning Windows domain controllers and cloud services Custom PowerShell functions and modules integrated into Ansible workflows Robust validation and error handling for usernames, email addresses, and dates Security-focused design ensuring timely access revocation and auditability Idempotent, production-ready playbooks suitable for scheduled and event-driven execution Impact: Reduced offboarding time from manual, error-prone processes to a fully automated workflow completed in minutes, significantly improving security posture and operational consistency.","title":"Hybrid AD &amp; Microsoft 365 Deprovisioning with Ansible"},{"location":"projects/ansible.html#employee-onboarding","text":"","title":"Employee Onboarding"},{"location":"projects/ansible.html#automated-hybrid-ad-microsoft-365-enterprise-service-provisioning-with-ansible","text":"Built a comprehensive Ansible-based employee onboarding automation that provisions user access across Active Directory, Microsoft 365, and internal enterprise systems from a single workflow. The playbook creates new Active Directory users, securely generates randomized credentials, and provisions corresponding Microsoft 365 accounts with unique passwords. It integrates PowerShell automation to process CSV exports from network printers, generating and assigning new printer access codes for incoming employees. Additional tasks provision accounts across supporting internal services to ensure day-one readiness. Prior to a ticketing system migration, the automation also integrated directly with Jira, automatically responding to onboarding tickets with status updates and completion details. Key highlights: End-to-end identity provisioning across on-prem and cloud environments Secure password generation and credential handling PowerShell-driven printer access automation using CSV data sources Multi-service account creation beyond AD and M365 Ticket-driven automation with automated Jira responses Idempotent, reusable Ansible playbooks designed for scale Impact: Reduced onboarding time from hours to minutes, eliminated manual provisioning errors, and delivered consistent, auditable access for new employees on their first day.","title":"Automated Hybrid AD, Microsoft 365 &amp; Enterprise Service Provisioning with Ansible"},{"location":"projects/ansible.html#proactive-service-remediation","text":"","title":"Proactive Service Remediation"},{"location":"projects/ansible.html#public-printing-infrastructure-stability-with-ansible","text":"Developed a scheduled Ansible automation to proactively stabilize a failing public printing service that frequently required manual Windows service restarts across multiple office locations. Using Ansible with Semaphore, I implemented a daily, off-hours playbook that automatically resets the affected Windows service when all offices were closed. This prevented cascading failures that previously triggered waves of support calls as offices opened throughout the day. Key highlights: Scheduled, unattended remediation using Ansible and Semaphore Windows service automation across distributed environments Proactive reliability engineering instead of reactive support Safe execution window aligned with business hours Impact: Eliminated recurring service outages, significantly reduced support call volume, and freed IT staff from repetitive manual interventions while improving service availability for patrons.","title":"Public Printing Infrastructure Stability with Ansible"},{"location":"projects/ansible.html#stability-for-mission-critical-systems","text":"","title":"Stability for Mission-Critical Systems"},{"location":"projects/ansible.html#accounting-system-automation-remediation-with-ansible","text":"Implemented a scheduled Ansible playbook to proactively stabilize a mission-critical accounting application running on Windows Server that was prone to service crashes. Prior to automation, failures frequently triggered urgent escalations and operational disruption for the accounting team. The playbook performs a controlled weekly restart of the application services during a safe maintenance window, preventing the recurring crashes that previously required manual intervention. Key highlights: Windows service automation for line-of-business applications Scheduled preventive maintenance using Ansible Zero-touch execution with predictable recovery behavior Business-aligned maintenance windows to avoid user impact Impact: Eliminated recurring outages, prevented high-stress incident escalations, and restored confidence for non-technical stakeholders by ensuring consistent system availability.","title":"Accounting System Automation &amp; Remediation with Ansible"},{"location":"projects/ansible.html#pii-data-sanitization","text":"","title":"PII Data Sanitization"},{"location":"projects/ansible.html#public-folder-security-on-file-servers-with-ansible","text":"Implemented a scheduled Ansible automation to securely manage a shared file server directory used for inbound scanned documents containing highly sensitive personally identifiable information (PII), including social insurance numbers and banking details. A manual deletion process was initially proposed, requiring staff to regularly clear the directory. This approach was unreliable, difficult to enforce, and vulnerable to being missed during high-priority IT incidents. To eliminate human error, I built an Ansible playbook that securely connects to the file server and automatically deletes the directory contents each evening after business hours. Key highlights: Security-first automation for sensitive data handling Elimination of manual, error-prone processes Scheduled execution outside business hours to avoid operational impact Consistent, auditable enforcement of data retention policies Impact: Significantly reduced the risk of sensitive data exposure, ensured consistent compliance with internal data-handling policies, and removed a fragile manual task from daily IT operations.","title":"Public Folder Security on File Servers with Ansible"},{"location":"projects/ansible.html#account-auditing-and-reporting","text":"","title":"Account Auditing and Reporting"},{"location":"projects/ansible.html#active-directory-microsoft-365-with-ansible","text":"Designed and implemented an Ansible-based auditing and reporting solution to continuously assess identity and device hygiene across on-prem Active Directory and Microsoft 365. The automation polls domain controllers to identify stale computer objects that have not checked in for extended periods, enabling the IT services team to cross-reference devices against the asset inventory to confirm decommissioning or recovery. This significantly reduced Active Directory object sprawl and improved directory accuracy. The playbook also audits user account activity, identifying inactive, disabled, and locked accounts. These reports were used to validate account lifecycle events against HR-provided employee rosters, reducing missed off-boardings and strengthening the organization\u2019s security posture. In parallel, the automation performs Microsoft 365 user and license audits, correlating cloud accounts with on-prem activity to identify accounts that should be deactivated and licenses reclaimed. Key highlights: Hybrid identity auditing across AD and Microsoft 365 Detection of stale devices and inactive users Cost control through license reclamation Security posture improvement via reduced orphaned accounts CSV-based reporting published to shared locations for cross-team review Impact: Improved directory accuracy, reduced security risk from dormant identities, lowered Microsoft 365 licensing costs, and provided IT leadership with clear, actionable audit data for lifecycle management.","title":"Active Directory &amp; Microsoft 365 with Ansible"},{"location":"projects/ansible.html#digital-signage-platform","text":"","title":"Digital Signage Platform"},{"location":"projects/ansible.html#custom-linux-distribution-automation-with-ansible","text":"Architected and deployed a fully automated digital signage platform managed end-to-end with Ansible, replacing an unreliable, freemium Windows-based solution that had effectively become abandonware. The legacy system caused frequent outages, frozen players, disruptive OS notifications, and required on-site manual intervention\u2014often involving ladder access to power-cycle devices. Windows updates, advertisements, and OS instability made reliable video playback impossible at scale. To solve this, I built a custom minimal Debian-based distribution, designed specifically for digital signage reliability. The operating system installation was fully automated using Debian preseed, producing a custom ISO with no interactive setup. A dedicated systemd service ensured the latest campaign video played continuously and reliably on boot. A suite of Ansible playbooks provided centralized control of all signage players across multiple remote branches, enabling: Remote start/stop of signage playback Scheduled nightly content updates from a central file server Remote software updates and controlled reboots Fleet-wide management with no physical access required For resiliency, a Cockpit web UI was deployed on each player, allowing manual recovery and control if Ansible connectivity was unavailable. Key highlights: Custom Linux OS engineering for single-purpose reliability Ansible-driven fleet management across geographically distributed sites systemd-based application orchestration Zero-touch provisioning with Debian preseed Fallback web management via Cockpit Impact: Eliminated routine on-site service visits, drastically reduced support calls related to digital signage failures, and transformed digital signage from a recurring operational burden into a stable, self-maintaining platform\u2014freeing the IT services team to focus on higher-value work.","title":"Custom Linux Distribution &amp; Automation with Ansible"},{"location":"projects/ansible.html#ssl-certificate-management","text":"","title":"SSL Certificate Management"},{"location":"projects/ansible.html#automated-ssl-enablement-with-ansible","text":"Identified and remediated a security gap where internally hosted web applications were operating over unencrypted HTTP, exposing sensitive internal traffic. The organization underestimated the value of SSL due to the perceived complexity of managing custom certificates across multiple systems. Collaborated with web developers to obtain a wildcard SSL certificate aligned with the organization\u2019s domain, eliminating browser warnings and enabling encrypted communication without per-machine certificate installation. Built an Ansible playbook to centrally deploy and renew SSL certificates across multiple internal web applications\u2014including the inventory system, ticketing platform, and staff intranet\u2014with a single execution. This ensured consistent HTTPS enforcement and simplified certificate lifecycle management. As the environment evolved, the applications were consolidated behind HAProxy, and the automation was extended to update certificates and reload services centrally. Key highlights: Security posture improvement through encrypted internal communications Wildcard SSL strategy to simplify trust management One-click certificate deployment and renewal using Ansible Cross-team collaboration with development teams Scalable evolution to centralized TLS termination with HAProxy Impact: Eliminated insecure HTTP usage, removed browser trust warnings, simplified certificate renewals, and ensured consistent, encrypted access to internal services with minimal operational overhead. Ubuntu Website OS & Containerized Development Automation with Ansible Modernized the corporate website infrastructure by transitioning from a single, static Ubuntu VM to LXC (Linux container) hosting, enabling faster deployments, easier updates, and greater development agility. Using Ansible, I automated website backups, container snapshots, and local replication of the production environment. This allowed web developers to work locally on an exact copy of the live site without risking downtime or production errors. Key highlights: Containerized hosting for improved deployment velocity and scalability Automated backups and snapshots for website protection and quick recovery Local development replication for safe, parallel testing and feature development Reduced errors and downtime by removing manual deployment steps Impact: Empowered web developers to iterate rapidly while ensuring the corporate website remained stable and highly available, all with minimal manual intervention.","title":"Automated SSL Enablement with Ansible"},{"location":"projects/ansible.html#zero-touch-website-os-upgrade","text":"","title":"Zero-Touch Website OS Upgrade"},{"location":"projects/ansible.html#ubuntu-os-upgrade-with-ansible","text":"Automated the upgrade of a corporate website VM from Ubuntu 22.04 to 24.04, eliminating a previously manual, multi-hour process that risked significant downtime. Using Ansible playbooks and a staged local VM environment, I implemented a zero-touch upgrade process that reduced website downtime from hours to just a few minutes. The solution was fully repeatable and required minimal manual intervention, allowing operations to run smoothly without disrupting users. Key highlights: Zero-touch OS upgrades for minimal downtime Staged testing environment to validate upgrades before production Automated, repeatable playbooks for consistent results Business continuity maintained with near-invisible service impact Impact: Transformed a time-consuming, risky maintenance task into a fast, reliable, automated operation, impressing stakeholders and improving operational confidence in future upgrades.","title":"Ubuntu OS Upgrade with Ansible"},{"location":"projects/homelab.html","text":"HomeLab I started a homelab because I wanted a space where I could learn by doing, without limits, approvals, or risk to production systems. This is essentially a personal space to experiment, break things, rebuild them, and understand why they work the way they do. Early on, I learned an important lesson: define the goal first. It\u2019s easy to get caught up buying powerful hardware \u201cjust in case,\u201d but a homelab is most effective when it grows to meet real needs. Building only what you need keeps it focused, affordable, and intentional. Beyond the technical side, there\u2019s also genuine satisfaction in it. Designing and maintaining systems that actually do something useful, espeically for my family, gives me great satisifaction. Even if it's on a small scale... it scratches both my creative and problem-solving itch. HomeLab Use Learning & Skill Development The homelab gives me a safe environment to sharpen real-world IT skills. Whether it\u2019s networking concepts that map to certifications, system administration, automation, or troubleshooting, I can test ideas without fear of consequences. Let's be honest here, if my child can't watch the latest episode of Bluey, or printing is disrupted for a couple hours, the only blow back I am going to face is from my spouse during that time. In reality, I fear my spouse more than I fear any manager or CEO. Self-Hosting & Control One of the biggest motivators was reclaiming control from large cloud providers. Hosting my own services means understanding exactly where my data lives, how it\u2019s secured, and how it\u2019s accessed. It enables me to employ tangible concepts that can be used in the workplace, especially in those rare edge-cases. Media, Storage, and Backups My homelab serves as the backbone for media delivery, centralized storage, and data protection. Media services like Jellyfin and Plex run alongside a storage architecture designed for resiliency, scalability, and full ownership of my data. Storage is distributed across three nodes using Ceph, providing fault tolerance and high availability for workloads that require it. For large files and media libraries, I also maintain a dedicated Network Attached Storage (NAS), optimized for capacity and throughput. The NAS plays a critical role in my backup strategy. Containers, virtual machines, and other essential workloads are regularly backed up to it, and critical data is synchronized with cloud providers such as OneDrive and Google Drive. This layered approach effectively implements a 3-2-1-style backup strategy, ensuring data remains protected even in the event of catastrophic hardware or site failure. Services & Experiments My homelab hosts a variety of services: from personal websites and internal tools to smart home automation and network services like printing and scanning. It\u2019s a sandbox where I can run workloads that would normally live in someone else\u2019s cloud\u2026 and save my credit card in the process. Some services, like my print and scanning servers, simply can\u2019t run in a public cloud, making self-hosting the only practical option. Virtualization & Containers My homelab leverages virtualization and containerization to simulate complex environments, test deployments, and experiment with architectures that would be difficult or costly elsewhere. I work with technologies including Kubernetes, LXD/LXC, Docker, and Ceph, enabling flexible and resilient infrastructure for both learning and practical projects. HomeLab Approach I didn\u2019t start with perfect hardware\u2014and that\u2019s the point. My homelab began with an old PC and grew over time, expanding with inherited appliances, like a NAS from my father, and recently-modern PCs I rescued from being discarded. It\u2019s never been about having the latest or fastest equipment\u2014it\u2019s about the journey. A homelab doesn\u2019t need to be career-driven. It can be about curiosity, convenience, or just experimenting for fun. I don\u2019t need 1ms latency or enterprise-grade performance; I just need a space to meet my digital needs and explore ideas freely. For me, the mentality is simple: Why not? Evolution of the HomeLab From Proxmox to MicroCloud My homelab journey began with Proxmox VE. Having used it in a professional environment, it felt familiar and worked reliably right out of the box. It\u2019s also the platform most commonly recommended across YouTube and homelab communities when people are just getting started\u2014and for good reason. Over time, though, I realized my goals had outgrown simple VM management. Hosting virtual machines directly on my primary network quickly became cumbersome: managing individual public IPs, firewall rules, SSL termination, and service exposure added unnecessary complexity. While Proxmox does support clustering, I found that once I started working more heavily with containers, its customized Linux kernel and LXC implementation limited the experience more than I expected. What I really wanted was hands-on experience with clustering and a more cloud-style infrastructure\u2014something that aligned closely with real-world Linux environments and skills I could transfer beyond the homelab. I accidentally stumbled upon Canonical\u2019s Ubuntu MicroCloud, and it immediately felt like home. It gave me fine-grained control over isolated networks, ingress and egress traffic, and service exposure. Containers and virtual machines could each live on their own isolated networks, and I could selectively expose services only when and how I needed to. Built on stock Ubuntu and leveraging LXD, MicroCeph, and MicroOVN, MicroCloud offers seamless clustering with minimal overhead. It\u2019s lightweight, scales easily, and runs exceptionally well on low-power and ARM hardware\u2014making it an ideal foundation for experimentation with modern, scalable infrastructure. MicroCloud over Proxmox Standard Linux First MicroCloud runs on stock Ubuntu Server. Every tool, workflow, and troubleshooting step maps directly to real-world Linux environments. There\u2019s no walled garden\u2014just Linux. True Hyper-Converged Clustering Clustering isn\u2019t an add-on; it\u2019s the core design. Storage and networking scale automatically as new nodes are introduced, without bolting on extra layers. Ideal for Small, Mixed Hardware From mini PCs and repurposed hardware to Raspberry Pis, MicroCloud performs well where heavier platforms begin to feel oversized. Containers as the Primary Abstraction LXD system containers are lightweight, fast, and well-suited for Linux services. Virtual machines remain available when full isolation or alternate operating systems are required. DevOps-Friendly by Design With native support for cloud-init and seamless integration with tools like Ansible and Terraform, MicroCloud aligns naturally with an infrastructure-as-code approach rather than a GUI-first workflow. What I Host Gitea Self-hosted Git service used for source control, issue tracking, and project collaboration. Gitea provides a lightweight alternative to hosted Git platforms, allowing full control over repositories, authentication, and integrations. In the homelab, it serves as the central source of truth for automation scripts, infrastructure code, and personal projects. The platform is complemented by self-hosted Gitea Actions runners, enabling CI/CD workflows to execute entirely within the homelab. These runners are used to build, test, and validate code, run automation checks, and prototype deployment pipelines without reliance on external CI providers, reinforcing a fully self-contained and reproducible development workflow. HAProxy Layer 4/7 load balancer and reverse proxy responsible for routing inbound traffic to internal services. HAProxy provides TLS termination, virtual host routing, and a single entry point for web-based applications. This setup mirrors real-world edge and ingress architectures used in production environments. Jellyfin Self-hosted media server for managing and streaming video content across the network. Jellyfin is used to centralize media storage while maintaining full ownership of data without reliance on external streaming platforms. It also serves as a testbed for storage performance, transcoding, and service reliability. Ollama Local AI inference service used to run large language models on-premises. Ollama allows experimentation with AI workloads without sending data to third-party cloud providers. In the homelab, it\u2019s used to explore GPU/CPU resource allocation, container isolation, and emerging AI infrastructure patterns. Print Server Virtual machine providing centralized network printing services across multiple subnets and protocols. Running as a full VM to support device drivers and broader OS compatibility, it integrates both IPv4 and IPv6 networking. This system reflects real enterprise requirements where containers are insufficient due to hardware or driver constraints. Semaphore Ansible Semaphore UI instance used to orchestrate and schedule automation jobs. It provides a controlled interface for running playbooks, managing inventories, and tracking execution history. In the homelab, Semaphore bridges infrastructure-as-code practices with repeatable operational workflows. Wekan Self-hosted Kanban board used for task tracking, project planning, and workflow visualization. Wekan supports personal productivity as well as structured project management, and serves as another example of replacing SaaS tools with self-hosted alternatives. Home Assistant Home automation platform used to centralize and automate smart home devices, sensors, and services. Home Assistant will integrate lighting, power monitoring, media playback, and environmental sensors into a single, locally controlled system without dependence on cloud-based vendor platforms. In the homelab, Home Assistant is being introduced as both a practical automation tool and a systems integration exercise, tying together networking, service discovery, container orchestration, and event-driven automation. It will also serve as a real-world example of stateful services, persistent storage, and long-running workloads within the MicroCloud/LXD environment. OpenWRT Router / Firewall Appliance Custom-built network edge device running an OpenWRT router on an x86 PC equipped with nine network interfaces. This system functions as the primary router, firewall, and internal switching fabric for the homelab, providing full control over traffic flow between internal networks, services, and external connectivity. Beyond basic routing, the appliance hosts additional network services including stateful firewalling, VLAN segmentation, and a WireGuard VPN, enabling secure remote access to internal services. Running OpenWRT on general-purpose hardware allows for flexibility, advanced customization, and enterprise-style networking features that exceed typical consumer router capabilities. This setup serves as a hands-on platform for learning and validating real-world networking concepts such as segmentation, zero-trust access patterns, VPN design, and firewall rule management, while acting as a stable foundation for the rest of the homelab infrastructure. Immich Self-hosted photo and video management platform used for automatic backup, organization, and browsing of personal media. Immich provides a modern, privacy-focused alternative to cloud photo services, offering features such as mobile uploads, metadata indexing, and timeline-based browsing. Within the homelab, Immich is used to evaluate storage performance, database-backed services, and media lifecycle management while maintaining full control over personal data. It also serves as a real-world workload for testing backups, snapshot strategies, and storage scaling within the MicroCloud/LXD environment. Podgrab Automated podcast aggregation and download service that fetches, organizes, and archives podcast episodes from subscribed feeds. Podgrab runs as a lightweight, always-on service that ensures episodes are captured and stored locally without reliance on third-party streaming platforms. In the homelab, Podgrab supports the broader self-hosting and data ownership philosophy, while acting as a simple but effective example of scheduled jobs, persistent storage, and low-resource containerized services. Kubernetes A dedicated virtual machine designed to host a Kubernetes cluster for container orchestration, service deployment, and experimentation with cloud-native architectures. This VM will provide a sandboxed environment to test multi-container applications, CI/CD pipelines, scaling strategies, and service networking, all within the homelab. The Kubernetes VM will allow hands-on experience with container scheduling, Helm charts, persistent volumes, and cluster monitoring, bridging the gap between single-node LXD containers and real-world distributed systems. It is also intended to serve as a platform for running microservices and experimental workloads without affecting existing stable services. Kiwix Offline Knowledge Server A self-hosted Kiwix server, where Kiwix is an open-source platform that enables offline access to websites by distributing them as compressed, searchable archives (ZIM files). It is commonly used to mirror resources such as Wikipedia, Python Documentation, and other useful content for use without an active internet connection. This service was implemented after learning about Kiwix and recognizing its real-world value following the Rogers nationwide internet outage in Canada, which disrupted internet access for a significant portion of the country. The outage highlighted the fragility of always-online assumptions and motivated the creation of a local, resilient knowledge base. By hosting curated offline archives within the homelab, this service ensures continued access to useful reference and educational materials during extended connectivity outages. This project emphasizes resilience-focused infrastructure design, thoughtful adoption of lesser-known technologies, and practical problem-solving beyond typical self-hosted services. Internal Debian Repository Mirror A privately hosted internal Debian package repository mirror, accessible only within the homelab and intentionally not exposed to the public internet. This mirror caches and serves Debian packages locally, allowing systems to install and update software without relying on external connectivity. This project was inspired by the Canada-wide Rogers outage, during which extended internet downtime revealed an unexpected dependency: even basic tasks\u2014such as playing a DVD on a computer\u2014required downloading additional software despite having physical media available. The experience highlighted how modern systems often assume constant internet access. In response, this mirror was implemented to ensure continued access to essential system and media software during network outages, improving overall infrastructure resilience. Beyond availability, the project also served as a practical exercise in repository hosting, package indexing, and secure internal distribution\u2014knowledge directly applicable to maintaining custom software repositories should the need arise in the future. This service demonstrates an understanding of software supply chains, offline-first design, and long-term infrastructure reliability, rather than simple service hosting","title":"Home Lab"},{"location":"projects/homelab.html#homelab","text":"I started a homelab because I wanted a space where I could learn by doing, without limits, approvals, or risk to production systems. This is essentially a personal space to experiment, break things, rebuild them, and understand why they work the way they do. Early on, I learned an important lesson: define the goal first. It\u2019s easy to get caught up buying powerful hardware \u201cjust in case,\u201d but a homelab is most effective when it grows to meet real needs. Building only what you need keeps it focused, affordable, and intentional. Beyond the technical side, there\u2019s also genuine satisfaction in it. Designing and maintaining systems that actually do something useful, espeically for my family, gives me great satisifaction. Even if it's on a small scale... it scratches both my creative and problem-solving itch.","title":"HomeLab"},{"location":"projects/homelab.html#homelab-use","text":"","title":"HomeLab Use"},{"location":"projects/homelab.html#learning-skill-development","text":"The homelab gives me a safe environment to sharpen real-world IT skills. Whether it\u2019s networking concepts that map to certifications, system administration, automation, or troubleshooting, I can test ideas without fear of consequences. Let's be honest here, if my child can't watch the latest episode of Bluey, or printing is disrupted for a couple hours, the only blow back I am going to face is from my spouse during that time. In reality, I fear my spouse more than I fear any manager or CEO.","title":"Learning &amp; Skill Development"},{"location":"projects/homelab.html#self-hosting-control","text":"One of the biggest motivators was reclaiming control from large cloud providers. Hosting my own services means understanding exactly where my data lives, how it\u2019s secured, and how it\u2019s accessed. It enables me to employ tangible concepts that can be used in the workplace, especially in those rare edge-cases.","title":"Self-Hosting &amp; Control"},{"location":"projects/homelab.html#media-storage-and-backups","text":"My homelab serves as the backbone for media delivery, centralized storage, and data protection. Media services like Jellyfin and Plex run alongside a storage architecture designed for resiliency, scalability, and full ownership of my data. Storage is distributed across three nodes using Ceph, providing fault tolerance and high availability for workloads that require it. For large files and media libraries, I also maintain a dedicated Network Attached Storage (NAS), optimized for capacity and throughput. The NAS plays a critical role in my backup strategy. Containers, virtual machines, and other essential workloads are regularly backed up to it, and critical data is synchronized with cloud providers such as OneDrive and Google Drive. This layered approach effectively implements a 3-2-1-style backup strategy, ensuring data remains protected even in the event of catastrophic hardware or site failure.","title":"Media, Storage, and Backups"},{"location":"projects/homelab.html#services-experiments","text":"My homelab hosts a variety of services: from personal websites and internal tools to smart home automation and network services like printing and scanning. It\u2019s a sandbox where I can run workloads that would normally live in someone else\u2019s cloud\u2026 and save my credit card in the process. Some services, like my print and scanning servers, simply can\u2019t run in a public cloud, making self-hosting the only practical option.","title":"Services &amp; Experiments"},{"location":"projects/homelab.html#virtualization-containers","text":"My homelab leverages virtualization and containerization to simulate complex environments, test deployments, and experiment with architectures that would be difficult or costly elsewhere. I work with technologies including Kubernetes, LXD/LXC, Docker, and Ceph, enabling flexible and resilient infrastructure for both learning and practical projects.","title":"Virtualization &amp; Containers"},{"location":"projects/homelab.html#homelab-approach","text":"I didn\u2019t start with perfect hardware\u2014and that\u2019s the point. My homelab began with an old PC and grew over time, expanding with inherited appliances, like a NAS from my father, and recently-modern PCs I rescued from being discarded. It\u2019s never been about having the latest or fastest equipment\u2014it\u2019s about the journey. A homelab doesn\u2019t need to be career-driven. It can be about curiosity, convenience, or just experimenting for fun. I don\u2019t need 1ms latency or enterprise-grade performance; I just need a space to meet my digital needs and explore ideas freely. For me, the mentality is simple: Why not?","title":"HomeLab Approach"},{"location":"projects/homelab.html#evolution-of-the-homelab","text":"","title":"Evolution of the HomeLab"},{"location":"projects/homelab.html#from-proxmox-to-microcloud","text":"My homelab journey began with Proxmox VE. Having used it in a professional environment, it felt familiar and worked reliably right out of the box. It\u2019s also the platform most commonly recommended across YouTube and homelab communities when people are just getting started\u2014and for good reason. Over time, though, I realized my goals had outgrown simple VM management. Hosting virtual machines directly on my primary network quickly became cumbersome: managing individual public IPs, firewall rules, SSL termination, and service exposure added unnecessary complexity. While Proxmox does support clustering, I found that once I started working more heavily with containers, its customized Linux kernel and LXC implementation limited the experience more than I expected. What I really wanted was hands-on experience with clustering and a more cloud-style infrastructure\u2014something that aligned closely with real-world Linux environments and skills I could transfer beyond the homelab. I accidentally stumbled upon Canonical\u2019s Ubuntu MicroCloud, and it immediately felt like home. It gave me fine-grained control over isolated networks, ingress and egress traffic, and service exposure. Containers and virtual machines could each live on their own isolated networks, and I could selectively expose services only when and how I needed to. Built on stock Ubuntu and leveraging LXD, MicroCeph, and MicroOVN, MicroCloud offers seamless clustering with minimal overhead. It\u2019s lightweight, scales easily, and runs exceptionally well on low-power and ARM hardware\u2014making it an ideal foundation for experimentation with modern, scalable infrastructure.","title":"From Proxmox to MicroCloud"},{"location":"projects/homelab.html#microcloud-over-proxmox","text":"Standard Linux First MicroCloud runs on stock Ubuntu Server. Every tool, workflow, and troubleshooting step maps directly to real-world Linux environments. There\u2019s no walled garden\u2014just Linux. True Hyper-Converged Clustering Clustering isn\u2019t an add-on; it\u2019s the core design. Storage and networking scale automatically as new nodes are introduced, without bolting on extra layers. Ideal for Small, Mixed Hardware From mini PCs and repurposed hardware to Raspberry Pis, MicroCloud performs well where heavier platforms begin to feel oversized. Containers as the Primary Abstraction LXD system containers are lightweight, fast, and well-suited for Linux services. Virtual machines remain available when full isolation or alternate operating systems are required. DevOps-Friendly by Design With native support for cloud-init and seamless integration with tools like Ansible and Terraform, MicroCloud aligns naturally with an infrastructure-as-code approach rather than a GUI-first workflow.","title":"MicroCloud over Proxmox"},{"location":"projects/homelab.html#what-i-host","text":"","title":"What I Host"},{"location":"projects/homelab.html#gitea","text":"Self-hosted Git service used for source control, issue tracking, and project collaboration. Gitea provides a lightweight alternative to hosted Git platforms, allowing full control over repositories, authentication, and integrations. In the homelab, it serves as the central source of truth for automation scripts, infrastructure code, and personal projects. The platform is complemented by self-hosted Gitea Actions runners, enabling CI/CD workflows to execute entirely within the homelab. These runners are used to build, test, and validate code, run automation checks, and prototype deployment pipelines without reliance on external CI providers, reinforcing a fully self-contained and reproducible development workflow.","title":"Gitea"},{"location":"projects/homelab.html#haproxy","text":"Layer 4/7 load balancer and reverse proxy responsible for routing inbound traffic to internal services. HAProxy provides TLS termination, virtual host routing, and a single entry point for web-based applications. This setup mirrors real-world edge and ingress architectures used in production environments.","title":"HAProxy"},{"location":"projects/homelab.html#jellyfin","text":"Self-hosted media server for managing and streaming video content across the network. Jellyfin is used to centralize media storage while maintaining full ownership of data without reliance on external streaming platforms. It also serves as a testbed for storage performance, transcoding, and service reliability.","title":"Jellyfin"},{"location":"projects/homelab.html#ollama","text":"Local AI inference service used to run large language models on-premises. Ollama allows experimentation with AI workloads without sending data to third-party cloud providers. In the homelab, it\u2019s used to explore GPU/CPU resource allocation, container isolation, and emerging AI infrastructure patterns.","title":"Ollama"},{"location":"projects/homelab.html#print-server","text":"Virtual machine providing centralized network printing services across multiple subnets and protocols. Running as a full VM to support device drivers and broader OS compatibility, it integrates both IPv4 and IPv6 networking. This system reflects real enterprise requirements where containers are insufficient due to hardware or driver constraints.","title":"Print Server"},{"location":"projects/homelab.html#semaphore","text":"Ansible Semaphore UI instance used to orchestrate and schedule automation jobs. It provides a controlled interface for running playbooks, managing inventories, and tracking execution history. In the homelab, Semaphore bridges infrastructure-as-code practices with repeatable operational workflows.","title":"Semaphore"},{"location":"projects/homelab.html#wekan","text":"Self-hosted Kanban board used for task tracking, project planning, and workflow visualization. Wekan supports personal productivity as well as structured project management, and serves as another example of replacing SaaS tools with self-hosted alternatives.","title":"Wekan"},{"location":"projects/homelab.html#home-assistant","text":"Home automation platform used to centralize and automate smart home devices, sensors, and services. Home Assistant will integrate lighting, power monitoring, media playback, and environmental sensors into a single, locally controlled system without dependence on cloud-based vendor platforms. In the homelab, Home Assistant is being introduced as both a practical automation tool and a systems integration exercise, tying together networking, service discovery, container orchestration, and event-driven automation. It will also serve as a real-world example of stateful services, persistent storage, and long-running workloads within the MicroCloud/LXD environment.","title":"Home Assistant"},{"location":"projects/homelab.html#openwrt-router-firewall-appliance","text":"Custom-built network edge device running an OpenWRT router on an x86 PC equipped with nine network interfaces. This system functions as the primary router, firewall, and internal switching fabric for the homelab, providing full control over traffic flow between internal networks, services, and external connectivity. Beyond basic routing, the appliance hosts additional network services including stateful firewalling, VLAN segmentation, and a WireGuard VPN, enabling secure remote access to internal services. Running OpenWRT on general-purpose hardware allows for flexibility, advanced customization, and enterprise-style networking features that exceed typical consumer router capabilities. This setup serves as a hands-on platform for learning and validating real-world networking concepts such as segmentation, zero-trust access patterns, VPN design, and firewall rule management, while acting as a stable foundation for the rest of the homelab infrastructure.","title":"OpenWRT Router / Firewall Appliance"},{"location":"projects/homelab.html#immich","text":"Self-hosted photo and video management platform used for automatic backup, organization, and browsing of personal media. Immich provides a modern, privacy-focused alternative to cloud photo services, offering features such as mobile uploads, metadata indexing, and timeline-based browsing. Within the homelab, Immich is used to evaluate storage performance, database-backed services, and media lifecycle management while maintaining full control over personal data. It also serves as a real-world workload for testing backups, snapshot strategies, and storage scaling within the MicroCloud/LXD environment.","title":"Immich"},{"location":"projects/homelab.html#podgrab","text":"Automated podcast aggregation and download service that fetches, organizes, and archives podcast episodes from subscribed feeds. Podgrab runs as a lightweight, always-on service that ensures episodes are captured and stored locally without reliance on third-party streaming platforms. In the homelab, Podgrab supports the broader self-hosting and data ownership philosophy, while acting as a simple but effective example of scheduled jobs, persistent storage, and low-resource containerized services.","title":"Podgrab"},{"location":"projects/homelab.html#kubernetes","text":"A dedicated virtual machine designed to host a Kubernetes cluster for container orchestration, service deployment, and experimentation with cloud-native architectures. This VM will provide a sandboxed environment to test multi-container applications, CI/CD pipelines, scaling strategies, and service networking, all within the homelab. The Kubernetes VM will allow hands-on experience with container scheduling, Helm charts, persistent volumes, and cluster monitoring, bridging the gap between single-node LXD containers and real-world distributed systems. It is also intended to serve as a platform for running microservices and experimental workloads without affecting existing stable services.","title":"Kubernetes"},{"location":"projects/homelab.html#kiwix-offline-knowledge-server","text":"A self-hosted Kiwix server, where Kiwix is an open-source platform that enables offline access to websites by distributing them as compressed, searchable archives (ZIM files). It is commonly used to mirror resources such as Wikipedia, Python Documentation, and other useful content for use without an active internet connection. This service was implemented after learning about Kiwix and recognizing its real-world value following the Rogers nationwide internet outage in Canada, which disrupted internet access for a significant portion of the country. The outage highlighted the fragility of always-online assumptions and motivated the creation of a local, resilient knowledge base. By hosting curated offline archives within the homelab, this service ensures continued access to useful reference and educational materials during extended connectivity outages. This project emphasizes resilience-focused infrastructure design, thoughtful adoption of lesser-known technologies, and practical problem-solving beyond typical self-hosted services.","title":"Kiwix Offline Knowledge Server"},{"location":"projects/homelab.html#internal-debian-repository-mirror","text":"A privately hosted internal Debian package repository mirror, accessible only within the homelab and intentionally not exposed to the public internet. This mirror caches and serves Debian packages locally, allowing systems to install and update software without relying on external connectivity. This project was inspired by the Canada-wide Rogers outage, during which extended internet downtime revealed an unexpected dependency: even basic tasks\u2014such as playing a DVD on a computer\u2014required downloading additional software despite having physical media available. The experience highlighted how modern systems often assume constant internet access. In response, this mirror was implemented to ensure continued access to essential system and media software during network outages, improving overall infrastructure resilience. Beyond availability, the project also served as a practical exercise in repository hosting, package indexing, and secure internal distribution\u2014knowledge directly applicable to maintaining custom software repositories should the need arise in the future. This service demonstrates an understanding of software supply chains, offline-first design, and long-term infrastructure reliability, rather than simple service hosting","title":"Internal Debian Repository Mirror"},{"location":"projects/powershell.html","text":"PowerShell Projects This section highlights a selection of my personal PowerShell projects and published modules, showcasing practical tools and automations built for systems management and reporting. PSGetLocalMonitors A PowerShell function that retrieves detailed monitor information including: manufacturer, model, and serial number from locally connected displays. The function queries Windows Management Instrumentation (WMI) and decodes Extended Display Identification Data (EDID), translating manufacturer codes into readable names for easy identification. PowerShell Gallery GitHub Repository Forked from: Get-Monitor-Information PSActiveDirectoryReports A PowerShell module for Active Directory reporting and management. It provides cmdlets for querying and generating reports on AD objects\u2014users, computers, groups, and organizational units, while automating routine administrative tasks and connectivity checks. PowerShell Gallery GitHub Repository PSCreateADForest A PowerShell module designed to quickly create new Active Directory forests and domain controllers. It's ideal for disaster recovery, setting up AD from scratch, or creating test and development environments efficiently, allowing for rapid deployment and teardown without starting from scratch. Perfect for your HomeLab ! PowerShell Gallery Github Repository CreateADUsers This is a small framework that leverages PowerShell and the Python module faker to generate random users for Active Directory and populates their profiles. I built this because I was tired of: Manually creating test users for every lab setup Dealing with inconsistent naming conventions across projects Wasting hours on repetitive data entry that should have been automated This is perfect for HomeLab enthusiasts, IT Administrators who want to prototype group policies or OU structures, or QA/Tester who want to rapidly spin up a test environment that mirrors a production-like AD deployment. Try using this along with my PSCreateADForest or PSActiveDirectoryReports modules! GitHub Repository PSEasyOpenSSH A PowerShell module to make it easier to manage OpenSSH Server on a Windows Host. I made this because I kept forgetting how many tilds I had put in a command (4 or 5) to install OpenSSH Server on Windows Server and Desktop OS. PowerShell Gallery Github Repository FreeActivate A Powershell module to activate Volume Licensed Windows Desktop and Windows Server OS on the command line. PowerShell Gallery Github Repository FreeDadJokes This is quite possibly the lamest thing I have ever made. PowerShell Gallery Github Repository","title":"Powershell"},{"location":"projects/powershell.html#powershell-projects","text":"This section highlights a selection of my personal PowerShell projects and published modules, showcasing practical tools and automations built for systems management and reporting.","title":"PowerShell Projects"},{"location":"projects/powershell.html#psgetlocalmonitors","text":"A PowerShell function that retrieves detailed monitor information including: manufacturer, model, and serial number from locally connected displays. The function queries Windows Management Instrumentation (WMI) and decodes Extended Display Identification Data (EDID), translating manufacturer codes into readable names for easy identification. PowerShell Gallery GitHub Repository Forked from: Get-Monitor-Information","title":"PSGetLocalMonitors"},{"location":"projects/powershell.html#psactivedirectoryreports","text":"A PowerShell module for Active Directory reporting and management. It provides cmdlets for querying and generating reports on AD objects\u2014users, computers, groups, and organizational units, while automating routine administrative tasks and connectivity checks. PowerShell Gallery GitHub Repository","title":"PSActiveDirectoryReports"},{"location":"projects/powershell.html#pscreateadforest","text":"A PowerShell module designed to quickly create new Active Directory forests and domain controllers. It's ideal for disaster recovery, setting up AD from scratch, or creating test and development environments efficiently, allowing for rapid deployment and teardown without starting from scratch. Perfect for your HomeLab ! PowerShell Gallery Github Repository","title":"PSCreateADForest"},{"location":"projects/powershell.html#createadusers","text":"This is a small framework that leverages PowerShell and the Python module faker to generate random users for Active Directory and populates their profiles. I built this because I was tired of: Manually creating test users for every lab setup Dealing with inconsistent naming conventions across projects Wasting hours on repetitive data entry that should have been automated This is perfect for HomeLab enthusiasts, IT Administrators who want to prototype group policies or OU structures, or QA/Tester who want to rapidly spin up a test environment that mirrors a production-like AD deployment. Try using this along with my PSCreateADForest or PSActiveDirectoryReports modules! GitHub Repository","title":"CreateADUsers"},{"location":"projects/powershell.html#pseasyopenssh","text":"A PowerShell module to make it easier to manage OpenSSH Server on a Windows Host. I made this because I kept forgetting how many tilds I had put in a command (4 or 5) to install OpenSSH Server on Windows Server and Desktop OS. PowerShell Gallery Github Repository","title":"PSEasyOpenSSH"},{"location":"projects/powershell.html#freeactivate","text":"A Powershell module to activate Volume Licensed Windows Desktop and Windows Server OS on the command line. PowerShell Gallery Github Repository","title":"FreeActivate"},{"location":"projects/powershell.html#freedadjokes","text":"This is quite possibly the lamest thing I have ever made. PowerShell Gallery Github Repository","title":"FreeDadJokes"},{"location":"projects/python.html","text":"Python Projects These projects range from serious IT lifesavers to quirky experiments born from curiosity and caffeine. Each project is hands-on, practical, and occasionally a little ridiculous. CreateADUsers This is a small framework that leverages PowerShell and the Python module faker to generate random users for Active Directory and populates their profiles. I built this because I was tired of: Manually creating test users for every lab setup Dealing with inconsistent naming conventions across projects Wasting hours on repetitive data entry that should have been automated This is perfect for HomeLab enthusiasts, IT Administrators who want to prototype group policies or OU structures, or QA/Tester who want to rapidly spin up a test environment that mirrors a production-like AD deployment. Try using this along with my PSCreateADForest or PSActiveDirectoryReports modules! GitHub Repository AD Domain Switch Over This project exists for one simple reason: I never want to drive to a hundred remote offices just to rejoin computers to a new domain. This is a lightweight Python framework that automates switching Windows machines from one Active Directory domain to another using encrypted configuration files and Group Policy. With some upfront planning and local admin access, machines unjoin the old domain, reboot, and join the new one automatically... no hands-on intervention required. The result is a repeatable, low-stress domain migration process that saves time, money, and a lot of expense reports. GitHub Repository Spice2JIRA A Python-based migration utility designed to help IT teams prepare and clean their data before moving from Spiceworks to Jira Service Management. This tool guides administrators through a step-by-step process to review and scrub ticket data... ensuring it\u2019s ready for import into Jira. It\u2019s built for IT departments of any size, especially useful for smaller teams looking to transition smoothly without losing historical ticket context. GitHub Repository Bitcoin Cash Vending Machine Like many great (and questionable) ideas, this project was born around the pandemic lockdowns. Armed with a Raspberry Pi, an Arduino, a handful of resistors, and a suspiciously cheap coin acceptor from Amazon, I built a mock Bitcoin Cash ATM. With a Wi-Fi connection and some loose change, this \u201cvending machine\u201d interacts with the Twilio API and the Bitcoin Cash blockchain to send small amounts of cryptocurrency to users who drop in coins and text their wallet address via SMS. GitHub Repository Ethereum Smart Contract Demo This was a presentation I made many years ago on how to deploy a smart contract on an Ethereum Blockchain and interact with it using Python. GitHub Repository","title":"Python"},{"location":"projects/python.html#python-projects","text":"These projects range from serious IT lifesavers to quirky experiments born from curiosity and caffeine. Each project is hands-on, practical, and occasionally a little ridiculous.","title":"Python Projects"},{"location":"projects/python.html#createadusers","text":"This is a small framework that leverages PowerShell and the Python module faker to generate random users for Active Directory and populates their profiles. I built this because I was tired of: Manually creating test users for every lab setup Dealing with inconsistent naming conventions across projects Wasting hours on repetitive data entry that should have been automated This is perfect for HomeLab enthusiasts, IT Administrators who want to prototype group policies or OU structures, or QA/Tester who want to rapidly spin up a test environment that mirrors a production-like AD deployment. Try using this along with my PSCreateADForest or PSActiveDirectoryReports modules! GitHub Repository","title":"CreateADUsers"},{"location":"projects/python.html#ad-domain-switch-over","text":"This project exists for one simple reason: I never want to drive to a hundred remote offices just to rejoin computers to a new domain. This is a lightweight Python framework that automates switching Windows machines from one Active Directory domain to another using encrypted configuration files and Group Policy. With some upfront planning and local admin access, machines unjoin the old domain, reboot, and join the new one automatically... no hands-on intervention required. The result is a repeatable, low-stress domain migration process that saves time, money, and a lot of expense reports. GitHub Repository","title":"AD Domain Switch Over"},{"location":"projects/python.html#spice2jira","text":"A Python-based migration utility designed to help IT teams prepare and clean their data before moving from Spiceworks to Jira Service Management. This tool guides administrators through a step-by-step process to review and scrub ticket data... ensuring it\u2019s ready for import into Jira. It\u2019s built for IT departments of any size, especially useful for smaller teams looking to transition smoothly without losing historical ticket context. GitHub Repository","title":"Spice2JIRA"},{"location":"projects/python.html#bitcoin-cash-vending-machine","text":"Like many great (and questionable) ideas, this project was born around the pandemic lockdowns. Armed with a Raspberry Pi, an Arduino, a handful of resistors, and a suspiciously cheap coin acceptor from Amazon, I built a mock Bitcoin Cash ATM. With a Wi-Fi connection and some loose change, this \u201cvending machine\u201d interacts with the Twilio API and the Bitcoin Cash blockchain to send small amounts of cryptocurrency to users who drop in coins and text their wallet address via SMS. GitHub Repository","title":"Bitcoin Cash Vending Machine"},{"location":"projects/python.html#ethereum-smart-contract-demo","text":"This was a presentation I made many years ago on how to deploy a smart contract on an Ethereum Blockchain and interact with it using Python. GitHub Repository","title":"Ethereum Smart Contract Demo"},{"location":"projects/shellscripts.html","text":"BASH Scripts Drupal 9 / 10 Install and Backup A series of scripts to install Drupal 9, Drupal 10, and backing up the sites. GitHub Repository Drupal Forums SSH Reverse Tunnel Punching holes through firewalls (with permission), using reverse SSH tunnels and just enough guardrails to keep things civilized. GitHub Repository Bitcoin Full Node Install This is a bash script that automates the installation and setup of a Bitcoin Core full node on a Debian 11 system. It handles downloading Bitcoin Core, creating a dedicated system user, configuring the firewall, and setting up the node to run as a background service that starts automatically on boot. GitHub Repository","title":"Shell Scripts"},{"location":"projects/shellscripts.html#bash-scripts","text":"","title":"BASH Scripts"},{"location":"projects/shellscripts.html#drupal-9-10-install-and-backup","text":"A series of scripts to install Drupal 9, Drupal 10, and backing up the sites. GitHub Repository Drupal Forums","title":"Drupal 9 / 10 Install and Backup"},{"location":"projects/shellscripts.html#ssh-reverse-tunnel","text":"Punching holes through firewalls (with permission), using reverse SSH tunnels and just enough guardrails to keep things civilized. GitHub Repository","title":"SSH Reverse Tunnel"},{"location":"projects/shellscripts.html#bitcoin-full-node-install","text":"This is a bash script that automates the installation and setup of a Bitcoin Core full node on a Debian 11 system. It handles downloading Bitcoin Core, creating a dedicated system user, configuring the firewall, and setting up the node to run as a background service that starts automatically on boot. GitHub Repository","title":"Bitcoin Full Node Install"}]}